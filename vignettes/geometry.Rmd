---
title: "The Factor Model as a Geometric Object"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{The Factor Model as a Geometric Object}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.height = 4.5,
  fig.align = "center",
  out.width = "90%"
)
```

*Why the internal covariance geometry of indicators constrains nothing about
their external causal relationships.*

## 2.1 Variables as Vectors in a Hilbert Space

We begin with a standard geometric reformulation. Let
$(\Omega, \mathcal{F}, P)$ be a probability space. Every mean-zero,
finite-variance random variable $X$ can be identified with an element of
the Hilbert space $L^2(\Omega, P)$, where the inner product is given by
covariance:

$$
\langle X_i,\, X_j \rangle \;=\; \mathrm{Cov}(X_i, X_j).
\tag{1}
$$

The induced norm is $\|X_i\| = \sqrt{\mathrm{Var}(X_i)}$, and the cosine
of the angle between two variable-vectors is exactly their correlation:

$$
\cos\theta_{ij} \;=\; \frac{\langle X_i,\, X_j\rangle}{\|X_i\|\,\|X_j\|}
\;=\; \mathrm{Corr}(X_i, X_j).
\tag{2}
$$

```{r fig1-angle-correlation, echo=FALSE, fig.cap="**Figure 1.** Two variable-vectors in $L^2$. The angle $\\theta$ between them satisfies $\\cos\\theta = \\mathrm{Corr}(X_i, X_j)$. From left to right: high positive correlation ($r = 0.9$, narrow angle), zero correlation ($r = 0$, orthogonal), and negative correlation ($r = -0.7$, obtuse angle).", fig.width=7.5, fig.height=3}
draw_vectors <- function(corr, main = "") {
  theta <- acos(max(-1, min(1, corr)))
  len <- 1
  # Xi along horizontal
  xi <- c(len, 0)
  # Xj at angle theta
  xj <- c(len * cos(theta), len * sin(theta))

  lim <- 1.3
  plot(NULL, xlim = c(-lim, lim), ylim = c(-0.3, lim),
       asp = 1, axes = FALSE, xlab = "", ylab = "", main = main)

  # draw arc
  if (abs(theta) > 0.05) {
    arc_t <- seq(0, theta, length.out = 60)
    arc_r <- 0.3
    lines(arc_r * cos(arc_t), arc_r * sin(arc_t),
          col = "#7d6608", lwd = 1.5)
    mid <- theta / 2
    text(0.38 * cos(mid), 0.38 * sin(mid), expression(theta),
         col = "#7d6608", cex = 1.1)
  }

  # arrows
  arrows(0, 0, xi[1], xi[2], col = "#c0392b", lwd = 2.5, length = 0.12)
  arrows(0, 0, xj[1], xj[2], col = "#2471a3", lwd = 2.5, length = 0.12)

  # labels
  text(xi[1] + 0.08, xi[2] - 0.06, expression(X[i]),
       col = "#c0392b", font = 2, cex = 1.1)
  text(xj[1] + 0.08, xj[2] + 0.06, expression(X[j]),
       col = "#2471a3", font = 2, cex = 1.1)

  # info
  deg <- round(theta * 180 / pi)
  text(0.55, -0.15, bquote(r == .(sprintf("%.1f", corr))),
       cex = 0.85, col = "#444")
  text(0.55, -0.25, bquote(theta == .(paste0(deg, "\u00b0"))),
       cex = 0.85, col = "#7d6608")
}

par(mfrow = c(1, 3), mar = c(1, 1, 2, 1))
draw_vectors(0.9,  "High positive (r = 0.9)")
draw_vectors(0.0,  "Uncorrelated (r = 0)")
draw_vectors(-0.7, "Negative (r = -0.7)")
```

Uncorrelated variables correspond to orthogonal vectors
($\theta_{ij} = 90°$); perfectly correlated variables are collinear
($\theta_{ij} = 0°$). This is the setting in which we will interpret
the factor model.


## 2.2 The One-Factor Model as a Geometric Decomposition

The basic univariate latent factor model posits that each (centred)
indicator $X_i$, $i = 1, \ldots, d$, decomposes as:

$$
X_i \;=\; \lambda_i\,\eta \;+\; \varepsilon_i,
\tag{3}
$$

where $\eta$ is a latent factor with $\mathrm{Var}(\eta) = 1$, the
loading $\lambda_i \neq 0$, and the residual $\varepsilon_i$ satisfies
$\mathrm{Cov}(\eta, \varepsilon_i) = 0$ and
$\mathrm{Cov}(\varepsilon_i, \varepsilon_j) = 0$ for $i \neq j$.
In $L^2$, equation (3) is an orthogonal decomposition of each
variable-vector into two components:

> **Geometric Reading of Eq. (3).** Each indicator $X_i$ is the sum of a
> *signal component* $\lambda_i \eta$, which lies along the one-dimensional
> subspace $\mathcal{S} = \mathrm{span}\{\eta\}$, and a *noise component*
> $\varepsilon_i$, which lies in a direction orthogonal to $\mathcal{S}$
> and orthogonal to every other $\varepsilon_j$. The loading $\lambda_i$
> is the signed length of the projection of $X_i$ onto $\eta$.

```{r fig2-fan-decomposition, echo=FALSE, fig.cap="**Figure 2.** Three indicator-vectors fanning from the latent axis $\\eta$. Each $X_i$ decomposes into a signal projection $\\lambda_i\\eta$ along the axis (dashed) and a noise residual $\\varepsilon_i$ perpendicular to it. The fan shape --- all indicators clustered around one axis --- is the geometric signature of a one-factor model.", fig.width=7, fig.height=5.5}
par(mfrow = c(1, 1), mar = c(1, 1, 1, 1))
eta_angle <- 0.35  # radians above horizontal

colors3 <- c("#c0392b", "#27ae60", "#8e44ad")
names3 <- c(expression(X[1]), expression(X[2]), expression(X[3]))
lambdas <- c(0.95, 0.75, 0.55)
noise_mag <- c(0.18, 0.28, 0.40)
noise_sign <- c(1, 1, 1)  # all on same side for clean fan shape

plot(NULL, xlim = c(-0.15, 1.5), ylim = c(-0.15, 1.35),
     asp = 1, axes = FALSE, xlab = "", ylab = "")

# eta axis (dashed line)
eta_dir <- c(cos(eta_angle), sin(eta_angle))
segments(-0.05 * eta_dir[1], -0.05 * eta_dir[2],
         1.3 * eta_dir[1], 1.3 * eta_dir[2],
         col = "#2471a3", lwd = 1.5, lty = 2)
text(1.35 * eta_dir[1], 1.35 * eta_dir[2],
     expression(eta), col = "#2471a3", font = 2, cex = 1.3)

perp_dir <- c(-sin(eta_angle), cos(eta_angle))

for (i in seq_along(lambdas)) {
  lam <- lambdas[i]
  nm <- noise_mag[i]
  ns <- noise_sign[i]

  # signal endpoint (projection on eta)
  sx <- lam * eta_dir[1]
  sy <- lam * eta_dir[2]

  # noise direction (perpendicular to eta)
  nx <- ns * perp_dir[1]
  ny <- ns * perp_dir[2]

  # full vector endpoint
  ex <- sx + nm * nx
  ey <- sy + nm * ny

  # decomposition: signal (dashed along eta)
  segments(0, 0, sx, sy, col = colors3[i], lwd = 1.5, lty = 3)
  # decomposition: noise (dashed perpendicular)
  segments(sx, sy, ex, ey, col = "grey70", lwd = 1.2, lty = 3)
  # right angle marker
  rsize <- 0.03
  ux <- eta_dir[1]; uy <- eta_dir[2]
  vx <- ns * perp_dir[1]; vy <- ns * perp_dir[2]
  lines(c(sx + rsize * ux, sx + rsize * ux + rsize * vx, sx + rsize * vx),
        c(sy + rsize * uy, sy + rsize * uy + rsize * vy, sy + rsize * vy),
        col = "grey60", lwd = 1)

  # full vector arrow
  arrows(0, 0, ex, ey, col = colors3[i], lwd = 2.5, length = 0.1)

  # X_i label at arrow tip (offset outward from eta axis)
  text(ex + 0.06, ey + 0.07, names3[i], col = colors3[i],
       font = 2, cex = 1.2)

  # lambda label below the projection point (on the eta-axis side)
  lmx <- sx - 0.06 * perp_dir[1]
  lmy <- sy - 0.06 * perp_dir[2]
  text(lmx, lmy, bquote(lambda[.(i)] * eta), col = colors3[i],
       cex = 0.85, pos = 1)

  # epsilon label beside the midpoint of noise segment (outward side)
  emx <- (sx + ex) / 2 + 0.06 * perp_dir[1]
  emy <- (sy + ey) / 2 + 0.06 * perp_dir[2]
  text(emx, emy, bquote(epsilon[.(i)]), col = "grey50", cex = 0.85)
}

# origin
points(0, 0, pch = 16, cex = 1.2)

# legend
legend("topleft", bty = "n", cex = 0.85,
       legend = c(expression(eta ~ "(latent axis)"),
                  expression(X[1]), expression(X[2]), expression(X[3]),
                  expression(epsilon ~ "(noise)")),
       col = c("#2471a3", colors3, "grey70"),
       lwd = c(1.5, 2.5, 2.5, 2.5, 1.2),
       lty = c(2, 1, 1, 1, 3))
```

### Covariance as inner product

Because the decomposition in (3) is orthogonal, the covariance between
any two indicators reduces to the inner product of their signal
components alone:

$$
\mathrm{Cov}(X_i, X_j) \;=\; \lambda_i\,\lambda_j.
\tag{4}
$$

The entire $d \times d$ covariance matrix has rank one, generated by
$\mathbf{\lambda}\mathbf{\lambda}^\top$. The internal geometry
is fully determined by the loadings. Fitting a one-factor model and
finding it adequate is equivalent to verifying that the indicator vectors
cluster tightly around a single axis in $L^2$.


## 2.3 The Structural Assumption as a Constraint on External Geometry

Now let $Y$ be any external variable --- an outcome, a treatment, or an
arbitrary covariate --- also viewed as a vector in $L^2$. The critical
observation is:

> **Key Insight.** The factor model (3) constrains only the *mutual*
> inner geometry of the vectors $\{X_1, \ldots, X_d\}$. It says
> **nothing** about the position of $Y$ in this space. The vector $Y$
> can point in any direction whatsoever while the indicators retain the
> exact same fan-shaped configuration around $\eta$.

To see this algebraically, decompose any variable's covariance with an
indicator:

$$
\mathrm{Cov}(X_i,\, Y) \;=\; \lambda_i\,\mathrm{Cov}(\eta,\,Y)
\;+\; \mathrm{Cov}(\varepsilon_i,\,Y).
\tag{5}
$$

The factor model imposes *no constraint* on
$\mathrm{Cov}(\varepsilon_i, Y)$. Two sharply different scenarios yield
identical internal geometry:

### Scenario A --- Structural

If the structural interpretation holds,
$\mathrm{Cov}(\varepsilon_i, Y) = 0$ for all $i$, so:

$$
\mathrm{Cov}(X_i,\, Y) \;=\; \lambda_i\,\mathrm{Cov}(\eta,\,Y),
\qquad \forall\; i.
\tag{6}
$$

The ratio of covariances across any two indicators equals the ratio of
loadings:

$$
\frac{\mathrm{Cov}(X_i,\,Y)}{\mathrm{Cov}(X_j,\,Y)}
\;=\; \frac{\lambda_i}{\lambda_j}, \qquad \forall\; i,j.
\tag{7}
$$

### Scenario B --- Non-structural

If some indicators have direct effects on $Y$, then some
$\mathrm{Cov}(\varepsilon_i, Y) \neq 0$, and equation (5) cannot be
simplified --- proportionality breaks.

```{r fig3-structural-vs-non, echo=FALSE, fig.cap="**Figure 3.** The same indicator fan under two scenarios. **Structural (A):** $Y$ projects only onto $\\eta$; its covariance with each $X_i$ is proportional to $\\lambda_i$. **Non-structural (B):** $Y$ also projects onto $\\varepsilon_3$'s direction, giving $X_3$ an extra association with $Y$ that breaks proportionality --- even though the fan of indicators is unchanged.", fig.width=8, fig.height=4.5}
draw_scenario <- function(structural = TRUE, main = "") {
  eta_angle <- 0.4
  eta_dir <- c(cos(eta_angle), sin(eta_angle))
  perp_dir <- c(-sin(eta_angle), cos(eta_angle))

  plot(NULL, xlim = c(-0.1, 1.4), ylim = c(-0.35, 1.2),
       asp = 1, axes = FALSE, xlab = "", ylab = "", main = main)

  # eta axis
  segments(-0.05 * eta_dir[1], -0.05 * eta_dir[2],
           1.2 * eta_dir[1], 1.2 * eta_dir[2],
           col = "#2471a3", lwd = 1.5, lty = 2)
  text(1.25 * eta_dir[1], 1.25 * eta_dir[2],
       expression(eta), col = "#2471a3", font = 2, cex = 1.1)

  lambdas <- c(0.85, 0.65, 0.55)
  noise_m <- c(0.18, 0.28, 0.40)
  noise_s <- c(1, 1, 1)
  colors3 <- c("#c0392b", "#27ae60", "#8e44ad")
  names3 <- c(expression(X[1]), expression(X[2]), expression(X[3]))

  eps3_dir <- NULL
  for (i in 1:3) {
    lam <- lambdas[i]
    nm <- noise_m[i]; ns <- noise_s[i]
    sx <- lam * eta_dir[1]; sy <- lam * eta_dir[2]
    nx <- ns * perp_dir[1]; ny <- ns * perp_dir[2]
    ex <- sx + nm * nx; ey <- sy + nm * ny
    if (i == 3) eps3_dir <- c(nx, ny)

    # faint decomposition
    segments(0, 0, sx, sy, col = colors3[i], lwd = 1, lty = 3)
    segments(sx, sy, ex, ey, col = "grey80", lwd = 1, lty = 3)
    arrows(0, 0, ex, ey, col = colors3[i], lwd = 2.5, length = 0.1)
    text(ex + 0.06, ey + 0.07, names3[i], col = colors3[i],
         font = 2, cex = 1.0)
  }

  # Y vector
  y_len <- 0.55
  ys_x <- y_len * eta_dir[1]; ys_y <- y_len * eta_dir[2]

  if (structural) {
    arrows(0, 0, ys_x, ys_y, col = "#2471a3", lwd = 3, length = 0.12)
    text(ys_x - 0.02, ys_y - 0.08, "Y", col = "#2471a3",
         font = 2, cex = 1.3)
    # annotation below the plot
    text(0.65, -0.18, expression("Y lies on" ~ eta * "-axis"),
         col = "#2471a3", cex = 0.8)
    text(0.65, -0.28, expression(Cov(epsilon[i], Y) == 0 ~ ~forall * i),
         col = "#2471a3", cex = 0.75)
  } else {
    # structural Y faintly
    arrows(0, 0, ys_x, ys_y, col = "#2471a3", lwd = 1.5, lty = 2,
           length = 0.08)
    text(ys_x - 0.02, ys_y - 0.08, "Y (structural)", col = "#2471a3",
         cex = 0.65, font = 3)

    # non-structural Y: tilted toward epsilon_3
    coupling <- 0.6
    tilt_x <- coupling * noise_m[3] * 0.8 * eps3_dir[1]
    tilt_y <- coupling * noise_m[3] * 0.8 * eps3_dir[2]
    yn_x <- ys_x + tilt_x; yn_y <- ys_y + tilt_y
    arrows(0, 0, yn_x, yn_y, col = "#e74c3c", lwd = 3, length = 0.12)
    text(yn_x + 0.07, yn_y + 0.06, "Y", col = "#e74c3c",
         font = 2, cex = 1.3)
    # deviation line
    segments(ys_x, ys_y, yn_x, yn_y, col = "#e74c3c", lwd = 1.5, lty = 2)

    # annotation below the plot
    text(0.65, -0.13, expression("Y tilts toward" ~ epsilon[3]),
         col = "#e74c3c", cex = 0.8)
    text(0.65, -0.22, expression(Cov(epsilon[3], Y) != 0),
         col = "#e74c3c", cex = 0.75)
    text(0.65, -0.31, "Proportionality breaks",
         col = "#e74c3c", cex = 0.75)
  }

  points(0, 0, pch = 16, cex = 1.2)
}

par(mfrow = c(1, 2), mar = c(1, 1, 2.5, 1))
draw_scenario(structural = TRUE,  main = "A: Structural")
draw_scenario(structural = FALSE, main = "B: Non-structural")
```


## 2.4 The Testable Implication, Geometrically

The structural assumption is equivalent to requiring that $Y$'s
projection onto the indicator subspace lies entirely in
$\mathcal{S} = \mathrm{span}\{\eta\}$:

> **Testable Geometric Constraint.** Under the structural
> interpretation, $Y$ must be orthogonal to every noise direction:
>
> $$\langle \varepsilon_i,\, Y \rangle = 0, \qquad i = 1, \ldots, d.$$
>
> VanderWeele and Vansteelandt's test checks whether the scaled
> associations $E(X_i \mid Z{=}z) / \lambda_i$ are constant across
> indicators $i$.

```{r fig4-proportionality, echo=FALSE, fig.cap="**Figure 4.** The proportionality test in action. *Left:* under a structural model, the raw covariances $\\mathrm{Cov}(X_i, Y)$ differ across indicators because loadings differ, but once divided by $\\lambda_i$ they collapse to a single constant (dashed line). *Right:* under a non-structural model, the last indicator deviates sharply after scaling, breaking the constant line.", fig.width=8.5, fig.height=4.5}
lambdas5 <- c(0.88, 0.82, 0.90, 0.78, 0.72)
cov_eta_y <- -0.25
colors5 <- c("#c0392b", "#27ae60", "#8e44ad", "#d68910", "#16a085")
short_labels <- c(expression(X[1]), expression(X[2]), expression(X[3]),
                  expression(X[4]), expression(X[5]))

draw_bars <- function(scenario = "structural", scaled = FALSE,
                      main = "") {
  if (scenario == "structural") {
    raw_covs <- lambdas5 * cov_eta_y
  } else {
    raw_covs <- lambdas5 * cov_eta_y
    raw_covs[5] <- -0.01
  }

  if (scaled) {
    vals <- raw_covs / lambdas5
    ylab <- expression(Cov(X[i], Y) / lambda[i])
  } else {
    vals <- raw_covs
    ylab <- expression(Cov(X[i], Y))
  }

  bar_col <- colors5
  if (scenario != "structural") bar_col[5] <- "#e74c3c"

  ylim <- range(c(vals, 0)) * 1.3
  bp <- barplot(vals, col = adjustcolor(bar_col, 0.75), border = NA,
                names.arg = rep("", 5), ylim = ylim,
                ylab = ylab, main = main, las = 1, cex.lab = 0.9)
  mtext(short_labels, side = 1, at = bp, line = 0.5, cex = 0.8)
  abline(h = 0, col = "grey80")

  # value labels
  text(bp, vals, labels = sprintf("%.2f", vals), pos = 3, cex = 0.7,
       col = bar_col, font = 2)

  # constant line for scaled structural
  if (scaled && scenario == "structural") {
    abline(h = cov_eta_y, col = "#2471a3", lwd = 2, lty = 2)
    mtext("constant", side = 4, at = cov_eta_y, las = 1,
          col = "#2471a3", cex = 0.7, line = 0.3)
  }

  # deviation marker for SWLS-like
  if (scaled && scenario != "structural") {
    abline(h = cov_eta_y, col = "#2471a3", lwd = 1.5, lty = 2)
    arrows(bp[5], cov_eta_y, bp[5], vals[5],
           col = "#e74c3c", lwd = 2, length = 0.06, code = 3)
    text(bp[5] + 0.4, mean(c(cov_eta_y, vals[5])),
         expression("" != ""), col = "#e74c3c", cex = 1.2, font = 2)
  }
}

par(mfrow = c(1, 2), mar = c(3, 4, 3, 2.5))
draw_bars("structural", scaled = TRUE,
          main = "Structural:\nscaled values constant")
draw_bars("swls", scaled = TRUE,
          main = "Non-structural:\nproportionality breaks")
```

When the test rejects --- as it does for the Satisfaction with Life Scale
and all-cause mortality --- it means the data reveal that $Y$'s vector
has non-negligible projections onto indicator-specific noise directions.
The internal fan is intact, but $Y$ does not align with its axis.
