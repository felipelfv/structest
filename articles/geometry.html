<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>The Factor Model as a Geometric Object • structest</title>
<!-- mathjax math --><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script><script>
  window.MathJax = {
    chtml: {
      fontURL: "https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2"
    }
  };
</script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="The Factor Model as a Geometric Object">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">structest</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/structest.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/geometry.html">The Factor Model as a Geometric Object</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>The Factor Model as a Geometric Object</h1>
            
      

      <div class="d-none name"><code>geometry.Rmd</code></div>
    </div>

    
    
<p><em>Why the internal covariance geometry of indicators constrains
nothing about their external causal relationships.</em></p>
<div class="section level2">
<h2 id="variables-as-vectors-in-a-hilbert-space">2.1 Variables as Vectors in a Hilbert Space<a class="anchor" aria-label="anchor" href="#variables-as-vectors-in-a-hilbert-space"></a>
</h2>
<p>We begin with a standard geometric reformulation. Let <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span> be a probability
space. Every mean-zero, finite-variance random variable <span class="math inline">\(X\)</span> can be identified with an element of
the Hilbert space <span class="math inline">\(L^2(\Omega, P)\)</span>,
where the inner product is given by covariance:</p>
<p><span class="math display">\[
\langle X_i,\, X_j \rangle \;=\; \mathrm{Cov}(X_i, X_j).
\tag{1}
\]</span></p>
<p>The induced norm is <span class="math inline">\(\|X_i\| =
\sqrt{\mathrm{Var}(X_i)}\)</span>, and the cosine of the angle between
two variable-vectors is exactly their correlation:</p>
<p><span class="math display">\[
\cos\theta_{ij} \;=\; \frac{\langle X_i,\, X_j\rangle}{\|X_i\|\,\|X_j\|}
\;=\; \mathrm{Corr}(X_i, X_j).
\tag{2}
\]</span></p>
<div class="figure" style="text-align: center">
<img src="geometry_files/figure-html/fig1-angle-correlation-1.png" class="r-plt" alt="**Figure 1.** Two variable-vectors in $L^2$. The angle $\theta$ between them satisfies $\cos\theta = \mathrm{Corr}(X_i, X_j)$. From left to right: high positive correlation ($r = 0.9$, narrow angle), zero correlation ($r = 0$, orthogonal), and negative correlation ($r = -0.7$, obtuse angle)." width="90%"><p class="caption">
<strong>Figure 1.</strong> Two variable-vectors in <span class="math inline">\(L^2\)</span>. The angle <span class="math inline">\(\theta\)</span> between them satisfies <span class="math inline">\(\cos\theta = \mathrm{Corr}(X_i, X_j)\)</span>.
From left to right: high positive correlation (<span class="math inline">\(r = 0.9\)</span>, narrow angle), zero correlation
(<span class="math inline">\(r = 0\)</span>, orthogonal), and negative
correlation (<span class="math inline">\(r = -0.7\)</span>, obtuse
angle).
</p>
</div>
<p>Uncorrelated variables correspond to orthogonal vectors (<span class="math inline">\(\theta_{ij} = 90°\)</span>); perfectly correlated
variables are collinear (<span class="math inline">\(\theta_{ij} =
0°\)</span>). This is the setting in which we will interpret the factor
model.</p>
</div>
<div class="section level2">
<h2 id="the-one-factor-model-as-a-geometric-decomposition">2.2 The One-Factor Model as a Geometric Decomposition<a class="anchor" aria-label="anchor" href="#the-one-factor-model-as-a-geometric-decomposition"></a>
</h2>
<p>The basic univariate latent factor model posits that each (centred)
indicator <span class="math inline">\(X_i\)</span>, <span class="math inline">\(i = 1, \ldots, d\)</span>, decomposes as:</p>
<p><span class="math display">\[
X_i \;=\; \lambda_i\,\eta \;+\; \varepsilon_i,
\tag{3}
\]</span></p>
<p>where <span class="math inline">\(\eta\)</span> is a latent factor
with <span class="math inline">\(\mathrm{Var}(\eta) = 1\)</span>, the
loading <span class="math inline">\(\lambda_i \neq 0\)</span>, and the
residual <span class="math inline">\(\varepsilon_i\)</span> satisfies
<span class="math inline">\(\mathrm{Cov}(\eta, \varepsilon_i) =
0\)</span> and <span class="math inline">\(\mathrm{Cov}(\varepsilon_i,
\varepsilon_j) = 0\)</span> for <span class="math inline">\(i \neq
j\)</span>. In <span class="math inline">\(L^2\)</span>, equation (3) is
an orthogonal decomposition of each variable-vector into two
components:</p>
<blockquote>
<p><strong>Geometric Reading of Eq. (3).</strong> Each indicator <span class="math inline">\(X_i\)</span> is the sum of a <em>signal
component</em> <span class="math inline">\(\lambda_i \eta\)</span>,
which lies along the one-dimensional subspace <span class="math inline">\(\mathcal{S} = \mathrm{span}\{\eta\}\)</span>, and
a <em>noise component</em> <span class="math inline">\(\varepsilon_i\)</span>, which lies in a direction
orthogonal to <span class="math inline">\(\mathcal{S}\)</span> and
orthogonal to every other <span class="math inline">\(\varepsilon_j\)</span>. The loading <span class="math inline">\(\lambda_i\)</span> is the signed length of the
projection of <span class="math inline">\(X_i\)</span> onto <span class="math inline">\(\eta\)</span>.</p>
</blockquote>
<div class="figure" style="text-align: center">
<img src="geometry_files/figure-html/fig2-fan-decomposition-1.png" class="r-plt" alt="**Figure 2.** Three indicator-vectors fanning from the latent axis $\eta$. Each $X_i$ decomposes into a signal projection $\lambda_i\eta$ along the axis (dashed) and a noise residual $\varepsilon_i$ perpendicular to it. The fan shape --- all indicators clustered around one axis --- is the geometric signature of a one-factor model." width="90%"><p class="caption">
<strong>Figure 2.</strong> Three indicator-vectors fanning from the
latent axis <span class="math inline">\(\eta\)</span>. Each <span class="math inline">\(X_i\)</span> decomposes into a signal projection
<span class="math inline">\(\lambda_i\eta\)</span> along the axis
(dashed) and a noise residual <span class="math inline">\(\varepsilon_i\)</span> perpendicular to it. The
fan shape — all indicators clustered around one axis — is the geometric
signature of a one-factor model.
</p>
</div>
<div class="section level3">
<h3 id="covariance-as-inner-product">Covariance as inner product<a class="anchor" aria-label="anchor" href="#covariance-as-inner-product"></a>
</h3>
<p>Because the decomposition in (3) is orthogonal, the covariance
between any two indicators reduces to the inner product of their signal
components alone:</p>
<p><span class="math display">\[
\mathrm{Cov}(X_i, X_j) \;=\; \lambda_i\,\lambda_j.
\tag{4}
\]</span></p>
<p>The entire <span class="math inline">\(d \times d\)</span> covariance
matrix has rank one, generated by <span class="math inline">\(\boldsymbol{\lambda}\boldsymbol{\lambda}^\top\)</span>.
The internal geometry is fully determined by the loadings. Fitting a
one-factor model and finding it adequate is equivalent to verifying that
the indicator vectors cluster tightly around a single axis in <span class="math inline">\(L^2\)</span>.</p>
</div>
</div>
<div class="section level2">
<h2 id="the-structural-assumption-as-a-constraint-on-external-geometry">2.3 The Structural Assumption as a Constraint on External
Geometry<a class="anchor" aria-label="anchor" href="#the-structural-assumption-as-a-constraint-on-external-geometry"></a>
</h2>
<p>Now let <span class="math inline">\(Y\)</span> be any external
variable — an outcome, a treatment, or an arbitrary covariate — also
viewed as a vector in <span class="math inline">\(L^2\)</span>. The
critical observation is:</p>
<blockquote>
<p><strong>Key Insight.</strong> The factor model (3) constrains only
the <em>mutual</em> inner geometry of the vectors <span class="math inline">\(\{X_1, \ldots, X_d\}\)</span>. It says
<strong>nothing</strong> about the position of <span class="math inline">\(Y\)</span> in this space. The vector <span class="math inline">\(Y\)</span> can point in any direction whatsoever
while the indicators retain the exact same fan-shaped configuration
around <span class="math inline">\(\eta\)</span>.</p>
</blockquote>
<p>To see this algebraically, decompose any variable’s covariance with
an indicator:</p>
<p><span class="math display">\[
\mathrm{Cov}(X_i,\, Y) \;=\; \lambda_i\,\mathrm{Cov}(\eta,\,Y)
\;+\; \mathrm{Cov}(\varepsilon_i,\,Y).
\tag{5}
\]</span></p>
<p>The factor model imposes <em>no constraint</em> on <span class="math inline">\(\mathrm{Cov}(\varepsilon_i, Y)\)</span>. Two
sharply different scenarios yield identical internal geometry:</p>
<div class="section level3">
<h3 id="scenario-a-structural">Scenario A — Structural<a class="anchor" aria-label="anchor" href="#scenario-a-structural"></a>
</h3>
<p>If the structural interpretation holds, <span class="math inline">\(\mathrm{Cov}(\varepsilon_i, Y) = 0\)</span> for
all <span class="math inline">\(i\)</span>, so:</p>
<p><span class="math display">\[
\mathrm{Cov}(X_i,\, Y) \;=\; \lambda_i\,\mathrm{Cov}(\eta,\,Y),
\qquad \forall\; i.
\tag{6}
\]</span></p>
<p>The ratio of covariances across any two indicators equals the ratio
of loadings:</p>
<p><span class="math display">\[
\frac{\mathrm{Cov}(X_i,\,Y)}{\mathrm{Cov}(X_j,\,Y)}
\;=\; \frac{\lambda_i}{\lambda_j}, \qquad \forall\; i,j.
\tag{7}
\]</span></p>
</div>
<div class="section level3">
<h3 id="scenario-b-non-structural">Scenario B — Non-structural<a class="anchor" aria-label="anchor" href="#scenario-b-non-structural"></a>
</h3>
<p>If some indicators have direct effects on <span class="math inline">\(Y\)</span>, then some <span class="math inline">\(\mathrm{Cov}(\varepsilon_i, Y) \neq 0\)</span>,
and equation (5) cannot be simplified — proportionality breaks.</p>
<div class="figure" style="text-align: center">
<img src="geometry_files/figure-html/fig3-structural-vs-non-1.png" class="r-plt" alt="**Figure 3.** The same indicator fan under two scenarios. **Structural (A):** $Y$ projects only onto $\eta$; its covariance with each $X_i$ is proportional to $\lambda_i$. **Non-structural (B):** $Y$ also projects onto $\varepsilon_3$'s direction, giving $X_3$ an extra association with $Y$ that breaks proportionality --- even though the fan of indicators is unchanged." width="90%"><p class="caption">
<strong>Figure 3.</strong> The same indicator fan under two scenarios.
<strong>Structural (A):</strong> <span class="math inline">\(Y\)</span>
projects only onto <span class="math inline">\(\eta\)</span>; its
covariance with each <span class="math inline">\(X_i\)</span> is
proportional to <span class="math inline">\(\lambda_i\)</span>.
<strong>Non-structural (B):</strong> <span class="math inline">\(Y\)</span> also projects onto <span class="math inline">\(\varepsilon_3\)</span>’s direction, giving <span class="math inline">\(X_3\)</span> an extra association with <span class="math inline">\(Y\)</span> that breaks proportionality — even
though the fan of indicators is unchanged.
</p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="the-testable-implication-geometrically">2.4 The Testable Implication, Geometrically<a class="anchor" aria-label="anchor" href="#the-testable-implication-geometrically"></a>
</h2>
<p>The structural assumption is equivalent to requiring that <span class="math inline">\(Y\)</span>’s projection onto the indicator
subspace lies entirely in <span class="math inline">\(\mathcal{S} =
\mathrm{span}\{\eta\}\)</span>:</p>
<blockquote>
<p><strong>Testable Geometric Constraint.</strong> Under the structural
interpretation, <span class="math inline">\(Y\)</span> must be
orthogonal to every noise direction:</p>
<p><span class="math display">\[\langle \varepsilon_i,\, Y \rangle = 0,
\qquad i = 1, \ldots, d.\]</span></p>
<p>VanderWeele and Vansteelandt’s test checks whether the scaled
associations <span class="math inline">\(E(X_i \mid Z{=}z) /
\lambda_i\)</span> are constant across indicators <span class="math inline">\(i\)</span>.</p>
</blockquote>
<div class="figure" style="text-align: center">
<img src="geometry_files/figure-html/fig4-proportionality-1.png" class="r-plt" alt="**Figure 4.** The proportionality test in action. *Left:* under a structural model, the raw covariances $\mathrm{Cov}(X_i, Y)$ differ across indicators because loadings differ, but once divided by $\lambda_i$ they collapse to a single constant (dashed line). *Right:* under a non-structural model, the last indicator deviates sharply after scaling, breaking the constant line." width="90%"><p class="caption">
<strong>Figure 4.</strong> The proportionality test in action.
<em>Left:</em> under a structural model, the raw covariances <span class="math inline">\(\mathrm{Cov}(X_i, Y)\)</span> differ across
indicators because loadings differ, but once divided by <span class="math inline">\(\lambda_i\)</span> they collapse to a single
constant (dashed line). <em>Right:</em> under a non-structural model,
the last indicator deviates sharply after scaling, breaking the constant
line.
</p>
</div>
<p>When the test rejects — as it does for the Satisfaction with Life
Scale and all-cause mortality — it means the data reveal that <span class="math inline">\(Y\)</span>’s vector has non-negligible projections
onto indicator-specific noise directions. The internal fan is intact,
but <span class="math inline">\(Y\)</span> does not align with its
axis.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Felipe Fontana Vieira.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
